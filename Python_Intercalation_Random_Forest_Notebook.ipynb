{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sixth-montreal",
   "metadata": {},
   "source": [
    "Let's import all the required libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import pandas as pd\n",
    "from scipy import ndimage as nd\n",
    "import skimage.morphology as skm\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "import cv2\n",
    "import pickle\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-specific",
   "metadata": {},
   "source": [
    "Here we initialize the 2 functions needed for later: applying all the filters and running the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_images(file_name):\n",
    "    \"\"\"\n",
    "    This function processes opened images\n",
    "    in order to produce a matrix for subsequent prediction.\n",
    "    It applies threshold and filters to the input image.\n",
    "    \"\"\"\n",
    "    global image\n",
    "    global mask\n",
    "    global thresh\n",
    "    global segmented\n",
    "    global df\n",
    "    global original_img_data\n",
    "    image = skimage.io.imread(file_name)\n",
    "    mask = skimage.io.imread(path + \"Mask_Final.tif\")\n",
    "    # Reshape original image to a single dimension array and add to a dataframe (1st column)\n",
    "    image_reshaped = image.reshape(-1)\n",
    "    df = pd.DataFrame()\n",
    "    df['source_image'] = image_reshaped\n",
    "    # Define sigmas for filers:gaussian,minimum and median. Median filters accepts only integers (int_sigmas)\n",
    "    sigmas = [0.3, 0.7, 1, 3, 5, 10]\n",
    "    int_sigmas = [i for i in sigmas if isinstance(i, (int))]\n",
    "    # Apply gaussian,minimum and median filters, reshape to single dimension array and add to the dataframe\n",
    "    for i in range(0, len(sigmas)):\n",
    "        gaussian_img = nd.gaussian_filter(image, sigma=sigmas[i])\n",
    "        gaussian_img_reshaped = gaussian_img.reshape(-1)\n",
    "        col_name_gauss = \"Gaussian_sigma_\" + str(sigmas[i])\n",
    "        # print(col_name_gauss)\n",
    "        df[col_name_gauss] = gaussian_img_reshaped\n",
    "\n",
    "        min_img = nd.minimum_filter(image, size=sigmas[i])\n",
    "        min_img_reshaped = min_img.reshape(-1)\n",
    "        col_name_min = \"Minimum_sigma_\" + str(sigmas[i])\n",
    "        # print(col_name_min)\n",
    "        df[col_name_min] = min_img_reshaped\n",
    "\n",
    "    for i in range(0, len(int_sigmas)):\n",
    "        median_img = nd.median_filter(image, size=int_sigmas[i])\n",
    "        median_img_reshaped = median_img.reshape(-1)\n",
    "        col_name_median = \"Median_sigma_\" + str(int_sigmas[i])\n",
    "        # print(col_name_median)\n",
    "        df[col_name_median] = median_img_reshaped\n",
    "    ############################################################\n",
    "    # Apply more filters-features, reshape and add to the dataframe\n",
    "    # CANNY EDGE\n",
    "    # edges = cv2.Canny(image, 100, 200)  # Image, min and max values\n",
    "    # edges1 = edges.reshape(-1)\n",
    "    # df['canny_edge'] = edges1\n",
    "    # ROBERTS EDGE\n",
    "    edge_roberts = roberts(image)\n",
    "    edge_roberts1 = edge_roberts.reshape(-1)\n",
    "    df['Roberts'] = edge_roberts1\n",
    "    # SOBEL\n",
    "    edge_sobel = sobel(image)\n",
    "    edge_sobel1 = edge_sobel.reshape(-1)\n",
    "    df['Sobel'] = edge_sobel1\n",
    "    # SCHARR\n",
    "    edge_scharr = scharr(image)\n",
    "    edge_scharr1 = edge_scharr.reshape(-1)\n",
    "    df['Scharr'] = edge_scharr1\n",
    "    # PREWITT\n",
    "    edge_prewitt = prewitt(image)\n",
    "    edge_prewitt1 = edge_prewitt.reshape(-1)\n",
    "    df['Prewitt'] = edge_prewitt1\n",
    "    # Reshape the manually labeled mask image and add as Label column to he dataframe\n",
    "    labeled_img = mask.reshape(-1)\n",
    "    df['Labels'] = labeled_img\n",
    "    # Remove the labels column and use the rest for prediction\n",
    "    original_img_data = df.drop(labels=[\"Labels\"], axis=1)\n",
    "    df = df[df.Labels != 0]\n",
    "\n",
    "\n",
    "def training_model(df):\n",
    "    \"\"\"\n",
    "      This function is used to\n",
    "      train the Random Forest Model\n",
    "      for pixel classification.\n",
    "      \"\"\"\n",
    "    global model_name\n",
    "    global model\n",
    "    # Define Y as the labels that you want to predict\n",
    "    Y = df[\"Labels\"].values\n",
    "    # Y_Encoded=LabelEncoder().fit_transform(Y)\n",
    "    # Define the independent variable X used for the prediction (the dataframe obtained before)\n",
    "    X = df.drop(labels=[\"Labels\"], axis=1)\n",
    "    # Split dataset into train and test with 80% train and 20% test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=20)\n",
    "    # Define the Random Forest Classifier model\n",
    "    model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Retrive info on the feature contributions and print them in order of importance\n",
    "    feature_list = list(X.columns)\n",
    "    feature_imp = pd.Series(model.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "    print(feature_imp)\n",
    "    # Save the trained model and make it available for future application\n",
    "    model_name = \"Random_Forest_Intercalation_Model\"\n",
    "    pickle.dump(model, open(model_name, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-candidate",
   "metadata": {},
   "source": [
    "Generate a random color scale from a modified Dark2 cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.linspace(0, 1, 256)\n",
    "np.random.shuffle(vals)\n",
    "mycmap = plt.cm.colors.ListedColormap(plt.cm.Dark2(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-restriction",
   "metadata": {},
   "source": [
    "Define input and output paths and read the spurce images and masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Federico/Documents/Python_Image_Processing/Test/\"\n",
    "image_name = \"test_image.tif\"\n",
    "file_name = path + image_name\n",
    "# out_folder = path + \"output/\"\n",
    "mask = skimage.io.imread(path + \"Mask_Final.tif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-chick",
   "metadata": {},
   "source": [
    "Now recall the process_images function to generate the image matrix for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_images(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-antibody",
   "metadata": {},
   "source": [
    "Visualize gray values histogram from source image - very useful for thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram, bin_edges = np.histogram(image, bins=255, range=(0, 255))\n",
    "plt.figure()\n",
    "plt.title(\"Source image Histogram\")\n",
    "plt.xlabel(\"Grayscale values\")\n",
    "plt.ylabel(\"Pixels\")\n",
    "plt.xlim([0.0, 255.0])\n",
    "plt.xticks(np.arange(0, 255, step=5))\n",
    "plt.plot(bin_edges[0:-1], histogram)\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-cookbook",
   "metadata": {},
   "source": [
    "Define threshold, get binary image,erode,dilate,fill holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_max = 20\n",
    "erode_pixels = 2\n",
    "thresh = image < threshold_max\n",
    "thresh = skm.binary_erosion(thresh, selem=skm.disk(erode_pixels))\n",
    "thresh = skm.binary_dilation(thresh, selem=skm.disk(erode_pixels))\n",
    "thresh = ndimage.binary_fill_holes(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-appraisal",
   "metadata": {},
   "source": [
    "Visualize the source image and the thresholded binary mask, side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.add_subplot(1, 2, 1)\n",
    "plt.title(\"Source Image\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "f.add_subplot(1, 2, 2)\n",
    "plt.title(\"Binary Mask\")\n",
    "plt.imshow(thresh, cmap='jet')\n",
    "# Visualize the source image and the manually-labeled mask, side-by-side\n",
    "f = plt.figure()\n",
    "f.add_subplot(1, 2, 1)\n",
    "plt.title(\"Source Image\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "f.add_subplot(1, 2, 2)\n",
    "plt.title(\"Labeled Mask\")\n",
    "plt.imshow(mask, cmap=mycmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparative-dining",
   "metadata": {},
   "source": [
    "Here we train or model based on the open images and respective masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-connection",
   "metadata": {},
   "source": [
    "Here we apply and test the trained model to get a prediction on the desired images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(original_img_data)\n",
    "segmented = prediction.reshape(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract 1 to the predicted image to obtain a binary image with values 0 or 1 only\n",
    "segmented = segmented - 1\n",
    "# Possible to add more binary operations to the obtained mask e.g. fill holes\n",
    "segmented = skm.binary_erosion(segmented, selem=skm.disk(2))\n",
    "segmented = ndimage.binary_fill_holes(segmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-suicide",
   "metadata": {},
   "source": [
    " Display side-by-side the original image, the thresholded one and the predicted with our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.add_subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "f.add_subplot(1, 2, 2)\n",
    "plt.title(\"Random Forest\")\n",
    "plt.imshow(segmented, cmap=mycmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-association",
   "metadata": {},
   "source": [
    "Now that we have our trained model, we want to apply it to all images in a folder to obtain the binary masks with threshold and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-ethernet",
   "metadata": {},
   "source": [
    "First we define all the arrays needed for opening and processing our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files_names = []\n",
    "images_arr = []\n",
    "segm_arr = []\n",
    "thresh_arr = []\n",
    "erode_arr = []\n",
    "dilate_arr = []\n",
    "fill_arr = []\n",
    "img_lbl_thr = []\n",
    "img_lbl_forest = []\n",
    "count_thr = []\n",
    "count_forest = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-ministry",
   "metadata": {},
   "source": [
    "Then we define the name of the model to load,the parameters for thresholding and the path of our images to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-colleague",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(model_name, 'rb'))\n",
    "erode_pixels = 2\n",
    "threshold = 20\n",
    "path2 = \"C:/Users/Federico/Documents/Python_Image_Processing/test_forest/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-summit",
   "metadata": {},
   "source": [
    "Now we loop thorugh all images in the folder and predict the binary masks, together with the thresholded images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-survival",
   "metadata": {},
   "source": [
    "Also, in the end, we count the total number of regions obtained with the 2 different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(os.listdir(path2))):\n",
    "    img_files_names.append(path2 + os.listdir(path2)[i])\n",
    "    images_arr.append(skimage.io.imread(img_files_names[i]))\n",
    "    process_images(img_files_names[i])\n",
    "    prediction = loaded_model.predict(original_img_data)\n",
    "    segmented = prediction.reshape(image.shape)\n",
    "    # Subtract 1 to the predicted image to obtain a binary image with values 0 or 1 only\n",
    "    segmented = segmented - 1\n",
    "    # Possible to add more binary operations to the obtained mask e.g. fill holes\n",
    "    segmented = skm.binary_erosion(segmented, selem=skm.disk(2))\n",
    "    segmented = ndimage.binary_fill_holes(segmented)\n",
    "    segm_arr.append(segmented)\n",
    "    open_img = skimage.io.imread(img_files_names[i])\n",
    "    # Threshold,Erode, dilate and fill holes from original image\n",
    "    thresholded = open_img < threshold\n",
    "    thresholded = skm.binary_erosion(thresholded, selem=skm.disk(erode_pixels))\n",
    "    thresholded = skm.binary_dilation(thresholded, selem=skm.disk(erode_pixels))\n",
    "    thresholded = ndimage.binary_fill_holes(thresholded)\n",
    "    thresh_arr.append(thresholded)\n",
    "    img_lbl_thr.append(label(thresh_arr[i]))\n",
    "    img_lbl_forest.append(label(segm_arr[i]))\n",
    "    # plt.imsave(out_folder + 'Segm_' + str(well[i]) + \"_\" + str(fov[i]) + \"_\" + str(time[i]) + 'min.jpg', img_lbl[i])\n",
    "    regions_thr = regionprops(img_lbl_thr[i])\n",
    "    regions_forest = regionprops(img_lbl_forest[i])\n",
    "    count_thr.append(len(regions_thr))\n",
    "    count_forest.append(len(regions_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-charleston",
   "metadata": {},
   "source": [
    "Here we visualize and compare 3 different images: original images, thresholded binary and Random Forest pixel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_col = 3\n",
    "fig_rows = 3\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(fig_rows, fig_col, 1)\n",
    "plt.imshow(images_arr[0], cmap=\"gray\")\n",
    "f.add_subplot(fig_rows, fig_col, 2)\n",
    "plt.title(\"Source Image\")\n",
    "plt.imshow(images_arr[1], cmap=\"gray\")\n",
    "f.add_subplot(fig_rows, fig_col, 3)\n",
    "plt.imshow(images_arr[2], cmap=\"gray\")\n",
    "\n",
    "f.add_subplot(fig_rows, fig_col, 4)\n",
    "plt.imshow(thresh_arr[0], cmap=mycmap)\n",
    "f.add_subplot(fig_rows, fig_col, 5)\n",
    "plt.title(\"Thresholded\")\n",
    "plt.imshow(thresh_arr[1], cmap=mycmap)\n",
    "f.add_subplot(fig_rows, fig_col, 6)\n",
    "plt.imshow(thresh_arr[2], cmap=mycmap)\n",
    "\n",
    "f.add_subplot(fig_rows, fig_col, 7)\n",
    "plt.imshow(segm_arr[0], cmap=mycmap)\n",
    "f.add_subplot(fig_rows, fig_col, 8)\n",
    "plt.title(\"Random Forest\")\n",
    "plt.imshow(segm_arr[1], cmap=mycmap)\n",
    "f.add_subplot(fig_rows, fig_col, 9)\n",
    "plt.imshow(segm_arr[2], cmap=mycmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
